{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c01f7a-f95a-48ad-8828-474341f592ae",
   "metadata": {},
   "source": [
    "### Preparing Training Dataset\n",
    "\n",
    "The main purpouse of this notebook is to generate the pickle file containing training dataset we use as an input in our main training script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178b1225-9cbf-4286-8d62-71826dd1fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.parquet as pq\n",
    "#import fastparquet as fp\n",
    "import tensorflow as tf\n",
    "# Set the URL to data\n",
    "data_path = './ITU_dataset/'             ## Path to where data is stored\n",
    "output_train_sim = data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c93a9-6d20-43d0-8318-35d32d863ad7",
   "metadata": {},
   "source": [
    "The training files (output file) include the information of each simulation as follows:\n",
    "\n",
    "1. Header line, indicating the name of the input file used for the simulation (the name of the input file contains the OBSS/PD-based threshold used in each case)\n",
    "\n",
    "2. Array with the throughput (in Mbps) obtained by each STA of the BSS of interest\n",
    "\n",
    "3. Array with the interference (in dBm) sensed by the AP of interest, from all the other APs.\n",
    "\n",
    "4. Array with the RSSI (in dBm) received by each STA of the BSS of interest, from its corresponding AP.\n",
    "\n",
    "5. Array with the average SINR (in dB) experienced by each STA of the BSS of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31627b80-272f-46cf-90d4-dd00cf4fbfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_file_name</th>\n",
       "      <th>throughput</th>\n",
       "      <th>interference</th>\n",
       "      <th>rssi</th>\n",
       "      <th>sinr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...</td>\n",
       "      <td>[34.24, 32.23, 32.68, 35.94]</td>\n",
       "      <td>[-57.27, -58.59, -52.75, -54.78]</td>\n",
       "      <td>[-65.0, -59.98, -91.26, -44.8]</td>\n",
       "      <td>[5.79, 7.02, 7.67, 6.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...</td>\n",
       "      <td>[34.26, 32.25, 32.69, 35.87]</td>\n",
       "      <td>[-57.27, -58.59, -52.75, -54.78]</td>\n",
       "      <td>[-65.0, -59.98, -91.26, -44.8]</td>\n",
       "      <td>[5.65, 7.57, 8.01, 5.95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...</td>\n",
       "      <td>[34.27, 32.25, 32.69, 35.89]</td>\n",
       "      <td>[-57.27, -58.59, -52.75, -54.78]</td>\n",
       "      <td>[-65.0, -59.98, -91.26, -44.8]</td>\n",
       "      <td>[5.79, 7.43, 8.01, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...</td>\n",
       "      <td>[34.23, 32.21, 32.63, 35.98]</td>\n",
       "      <td>[-57.27, -58.59, -52.75, -54.78]</td>\n",
       "      <td>[-65.0, -59.98, -91.26, -44.8]</td>\n",
       "      <td>[5.17, 6.98, 8.52, 6.65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...</td>\n",
       "      <td>[34.36, 32.24, 32.59, 35.94]</td>\n",
       "      <td>[-57.27, -58.59, -52.75, -54.78]</td>\n",
       "      <td>[-65.0, -59.98, -91.26, -44.8]</td>\n",
       "      <td>[6.2, 6.66, 7.84, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188575</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...</td>\n",
       "      <td>[35.52, 47.34]</td>\n",
       "      <td>[-52.33, -40.88]</td>\n",
       "      <td>[-93.56, -97.47, -85.51, -79.08]</td>\n",
       "      <td>[47.55, 55.97]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188576</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...</td>\n",
       "      <td>[35.55, 47.28]</td>\n",
       "      <td>[-52.33, -40.88]</td>\n",
       "      <td>[-93.56, -97.47, -85.51, -79.08]</td>\n",
       "      <td>[50.77, 52.47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188577</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...</td>\n",
       "      <td>[35.57, 47.27]</td>\n",
       "      <td>[-52.33, -40.88]</td>\n",
       "      <td>[-93.56, -97.47, -85.51, -79.08]</td>\n",
       "      <td>[49.52, 53.42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188578</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...</td>\n",
       "      <td>[35.66, 47.34]</td>\n",
       "      <td>[-52.33, -40.88]</td>\n",
       "      <td>[-93.56, -97.47, -85.51, -79.08]</td>\n",
       "      <td>[48.22, 54.06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188579</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...</td>\n",
       "      <td>[35.82, 47.22]</td>\n",
       "      <td>[-52.33, -40.88]</td>\n",
       "      <td>[-93.56, -97.47, -85.51, -79.08]</td>\n",
       "      <td>[47.15, 54.95]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188580 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_file_name  \\\n",
       "0        KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...   \n",
       "1        KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...   \n",
       "2        KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...   \n",
       "3        KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...   \n",
       "4        KOMONDOR SIMULATION 'sim_input_nodes_s000_v00...   \n",
       "...                                                   ...   \n",
       "188575   KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...   \n",
       "188576   KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...   \n",
       "188577   KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...   \n",
       "188578   KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...   \n",
       "188579   KOMONDOR SIMULATION 'sim_input_nodes_s999_v11...   \n",
       "\n",
       "                          throughput                      interference  \\\n",
       "0       [34.24, 32.23, 32.68, 35.94]  [-57.27, -58.59, -52.75, -54.78]   \n",
       "1       [34.26, 32.25, 32.69, 35.87]  [-57.27, -58.59, -52.75, -54.78]   \n",
       "2       [34.27, 32.25, 32.69, 35.89]  [-57.27, -58.59, -52.75, -54.78]   \n",
       "3       [34.23, 32.21, 32.63, 35.98]  [-57.27, -58.59, -52.75, -54.78]   \n",
       "4       [34.36, 32.24, 32.59, 35.94]  [-57.27, -58.59, -52.75, -54.78]   \n",
       "...                              ...                               ...   \n",
       "188575                [35.52, 47.34]                  [-52.33, -40.88]   \n",
       "188576                [35.55, 47.28]                  [-52.33, -40.88]   \n",
       "188577                [35.57, 47.27]                  [-52.33, -40.88]   \n",
       "188578                [35.66, 47.34]                  [-52.33, -40.88]   \n",
       "188579                [35.82, 47.22]                  [-52.33, -40.88]   \n",
       "\n",
       "                                    rssi                      sinr  \n",
       "0         [-65.0, -59.98, -91.26, -44.8]   [5.79, 7.02, 7.67, 6.2]  \n",
       "1         [-65.0, -59.98, -91.26, -44.8]  [5.65, 7.57, 8.01, 5.95]  \n",
       "2         [-65.0, -59.98, -91.26, -44.8]   [5.79, 7.43, 8.01, 6.0]  \n",
       "3         [-65.0, -59.98, -91.26, -44.8]  [5.17, 6.98, 8.52, 6.65]  \n",
       "4         [-65.0, -59.98, -91.26, -44.8]    [6.2, 6.66, 7.84, 6.0]  \n",
       "...                                  ...                       ...  \n",
       "188575  [-93.56, -97.47, -85.51, -79.08]            [47.55, 55.97]  \n",
       "188576  [-93.56, -97.47, -85.51, -79.08]            [50.77, 52.47]  \n",
       "188577  [-93.56, -97.47, -85.51, -79.08]            [49.52, 53.42]  \n",
       "188578  [-93.56, -97.47, -85.51, -79.08]            [48.22, 54.06]  \n",
       "188579  [-93.56, -97.47, -85.51, -79.08]            [47.15, 54.95]  \n",
       "\n",
       "[188580 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we can check how the output files looks depending on the scenario\n",
    "\n",
    "output_file_root_name = 'output_11ax_sr_simulations'\n",
    "column_names = [\"input_file_name\", \"throughput\", \"interference\", \"rssi\", \"sinr\"]\n",
    "\n",
    "\n",
    "# First we put the data from one experiment into pandas dataframe\n",
    "output_data_scene1_raw = pd.read_csv(data_path + output_file_root_name + '_sce1.txt', sep=\"\\n\", names=[\"raw_data\"])\n",
    "output_data_scene1 = pd.DataFrame()\n",
    "for x in range(len(column_names)):\n",
    "    output_data_scene1[column_names[x]] = output_data_scene1_raw[(output_data_scene1_raw.index + x) % 5== 0].reset_index(drop=True)\n",
    "\n",
    "# Clean the dataset and convert values to float\n",
    "output_data_scene1[\"throughput\"] = output_data_scene1[\"throughput\"].str.replace('f','')\n",
    "\n",
    "output_data_scene1[\"throughput\"] = pd.to_numeric(output_data_scene1[\"throughput\"], downcast=\"float\")\n",
    "output_data_scene1[\"interference\"] = pd.to_numeric(output_data_scene1[\"interference\"], downcast=\"float\")\n",
    "output_data_scene1[\"sinr\"] = pd.to_numeric(output_data_scene1[\"sinr\"], downcast=\"float\")\n",
    "\n",
    "for y in range(len(output_data_scene1['rssi'])):\n",
    "    output_data_scene1.at[y, 'rssi'] = [float(x) for x in output_data_scene1.at[y, 'rssi'].split(',')]\n",
    "\n",
    "# First we put the data from second experiment into pandas dataframe\n",
    "output_data_scene2_raw = pd.read_csv(data_path + output_file_root_name + '_sce2.txt', sep=\"\\n\", names=[\"raw_data\"], encoding = \"latin-1\")\n",
    "output_data_scene2 = pd.DataFrame()\n",
    "for x in range(len(column_names)):\n",
    "    output_data_scene2[column_names[x]] = output_data_scene2_raw[(output_data_scene2_raw.index + x) % 5== 0].reset_index(drop=True)\n",
    "\n",
    "# Convert values to float\n",
    "# output_data_scene2[\"throughput\"] = output_data_scene2[\"throughput\"].str.replace('«¤Ð\\x16d\\x9c\\x0235.05','0')\n",
    "\n",
    "list_of_weird_datapoints = []\n",
    "for y in range(len(output_data_scene2['throughput'])):\n",
    "    try:\n",
    "        output_data_scene2.at[y, 'throughput'] = [float(x) for x in output_data_scene2.at[y, 'throughput'].split(',')]\n",
    "        output_data_scene2.at[y, 'interference'] = [float(x) for x in output_data_scene2.at[y, 'interference'].split(',')]\n",
    "        output_data_scene2.at[y, 'rssi'] = [float(x) for x in output_data_scene2.at[y, 'rssi'].split(',')]\n",
    "        output_data_scene2.at[y, 'sinr'] = [float(x) for x in output_data_scene2.at[y, 'sinr'].split(',')]\n",
    "    except:\n",
    "        print(\"problematic index is:\", y)\n",
    "        list_of_weird_datapoints.append(y)\n",
    "\n",
    "# Drop them:\n",
    "output_data_scene2 = output_data_scene2.drop(list_of_weird_datapoints)\n",
    "output_data_scene2 = output_data_scene2.reset_index(drop=True)\n",
    "        \n",
    "#output_data_scene2[\"interference\"] = pd.to_numeric(output_data_scene2[\"interference\"], downcast=\"float\")\n",
    "#output_data_scene2[\"sinr\"] = pd.to_numeric(output_data_scene2[\"sinr\"], downcast=\"float\")\n",
    "\n",
    "output_data_scene1\n",
    "output_data_scene2\n",
    "\n",
    "\n",
    "\n",
    "# First we put the data from second experiment into pandas dataframe\n",
    "output_data_scene3_raw = pd.read_csv(data_path + output_file_root_name + '_sce3.txt', sep=\"\\n\", names=[\"raw_data\"], encoding = \"latin-1\")\n",
    "output_data_scene3 = pd.DataFrame()\n",
    "for x in range(len(column_names)):\n",
    "    output_data_scene3[column_names[x]] = output_data_scene3_raw[(output_data_scene3_raw.index + x) % 5== 0].reset_index(drop=True)\n",
    "\n",
    "# Convert values to float\n",
    "#output_data_scene3[\"throughput\"] = output_data_scene2[\"throughput\"].str.replace('«¤Ð\\x16d\\x9c\\x0235.05','0')\n",
    "\n",
    "list_of_weird_datapoints = []\n",
    "for y in range(len(output_data_scene3['throughput'])):\n",
    "    try:\n",
    "        output_data_scene3.at[y, 'throughput'] = [float(x) for x in output_data_scene3.at[y, 'throughput'].split(',')]\n",
    "        output_data_scene3.at[y, 'interference'] = [float(x) for x in output_data_scene3.at[y, 'interference'].split(',')]\n",
    "        output_data_scene3.at[y, 'rssi'] = [float(x) for x in output_data_scene3.at[y, 'rssi'].split(',')]\n",
    "        output_data_scene3.at[y, 'sinr'] = [float(x) for x in output_data_scene3.at[y, 'sinr'].split(',')]\n",
    "    except:\n",
    "        print(\"problematic index is:\", y)\n",
    "        list_of_weird_datapoints.append(y)\n",
    "\n",
    "# Drop them:\n",
    "#output_data_scene2 = output_data_scene2.drop(list_of_weird_datapoints)\n",
    "#output_data_scene2 = output_data_scene2.reset_index(drop=True)\n",
    "        \n",
    "#output_data_scene2[\"interference\"] = pd.to_numeric(output_data_scene2[\"interference\"], downcast=\"float\")\n",
    "#output_data_scene2[\"sinr\"] = pd.to_numeric(output_data_scene2[\"sinr\"], downcast=\"float\")\n",
    "\n",
    "output_data_scene1\n",
    "output_data_scene2\n",
    "output_data_scene3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8f787d-4bfe-4b1f-9140-fc25d5b6ad74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_file_name</th>\n",
       "      <th>throughput</th>\n",
       "      <th>interference</th>\n",
       "      <th>rssi</th>\n",
       "      <th>sinr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...</td>\n",
       "      <td>33.380001</td>\n",
       "      <td>-78.989998</td>\n",
       "      <td>[-70.51, -77.78, -70.43, -119.21]</td>\n",
       "      <td>1.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...</td>\n",
       "      <td>33.380001</td>\n",
       "      <td>-77.989998</td>\n",
       "      <td>[-70.51, -77.78, -70.43, -119.21]</td>\n",
       "      <td>1.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...</td>\n",
       "      <td>33.380001</td>\n",
       "      <td>-76.989998</td>\n",
       "      <td>[-70.51, -77.78, -70.43, -119.21]</td>\n",
       "      <td>1.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...</td>\n",
       "      <td>33.380001</td>\n",
       "      <td>-75.989998</td>\n",
       "      <td>[-70.51, -77.78, -70.43, -119.21]</td>\n",
       "      <td>1.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...</td>\n",
       "      <td>33.389999</td>\n",
       "      <td>-74.989998</td>\n",
       "      <td>[-70.51, -77.78, -70.43, -119.21]</td>\n",
       "      <td>1.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...</td>\n",
       "      <td>50.349998</td>\n",
       "      <td>-41.459999</td>\n",
       "      <td>[-107.02, -84.46]</td>\n",
       "      <td>110.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...</td>\n",
       "      <td>50.349998</td>\n",
       "      <td>-41.459999</td>\n",
       "      <td>[-107.02, -84.46]</td>\n",
       "      <td>110.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...</td>\n",
       "      <td>50.349998</td>\n",
       "      <td>-41.459999</td>\n",
       "      <td>[-107.02, -84.46]</td>\n",
       "      <td>110.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...</td>\n",
       "      <td>50.349998</td>\n",
       "      <td>-41.459999</td>\n",
       "      <td>[-107.02, -84.46]</td>\n",
       "      <td>110.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...</td>\n",
       "      <td>50.349998</td>\n",
       "      <td>-41.459999</td>\n",
       "      <td>[-107.02, -84.46]</td>\n",
       "      <td>110.349998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input_file_name  throughput  \\\n",
       "0       KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...   33.380001   \n",
       "1       KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...   33.380001   \n",
       "2       KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...   33.380001   \n",
       "3       KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...   33.380001   \n",
       "4       KOMONDOR SIMULATION 'sim_input_nodes_s0000_c-...   33.389999   \n",
       "...                                                  ...         ...   \n",
       "20995   KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...   50.349998   \n",
       "20996   KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...   50.349998   \n",
       "20997   KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...   50.349998   \n",
       "20998   KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...   50.349998   \n",
       "20999   KOMONDOR SIMULATION 'sim_input_nodes_s0999_c-...   50.349998   \n",
       "\n",
       "       interference                               rssi        sinr  \n",
       "0        -78.989998  [-70.51, -77.78, -70.43, -119.21]    1.480000  \n",
       "1        -77.989998  [-70.51, -77.78, -70.43, -119.21]    1.480000  \n",
       "2        -76.989998  [-70.51, -77.78, -70.43, -119.21]    1.480000  \n",
       "3        -75.989998  [-70.51, -77.78, -70.43, -119.21]    1.480000  \n",
       "4        -74.989998  [-70.51, -77.78, -70.43, -119.21]    1.480000  \n",
       "...             ...                                ...         ...  \n",
       "20995    -41.459999                  [-107.02, -84.46]  110.349998  \n",
       "20996    -41.459999                  [-107.02, -84.46]  110.349998  \n",
       "20997    -41.459999                  [-107.02, -84.46]  110.349998  \n",
       "20998    -41.459999                  [-107.02, -84.46]  110.349998  \n",
       "20999    -41.459999                  [-107.02, -84.46]  110.349998  \n",
       "\n",
       "[21000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_scene1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ddadd4-2e25-4cc9-adff-ca295a26a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_root_name = 'output_11ax_sr_simulations'\n",
    "column_names = [\"input_file_name\"]\n",
    "\n",
    "\n",
    "# First we put the data from first scenario into pandas dataframe\n",
    "data_scene1_raw = pd.read_csv(data_path + output_file_root_name + '_sce1.txt', sep=\"\\n\", names=[\"raw_data\"])\n",
    "data_scene1 = pd.DataFrame()\n",
    "for x in range(len(column_names)):\n",
    "    data_scene1[column_names[x]] = data_scene1_raw[(data_scene1_raw.index + x) % 5== 0].reset_index(drop=True)\n",
    "\n",
    "# Then we put the data from second scerion into pandas dataframe\n",
    "data_scene2_raw = pd.read_csv(data_path + output_file_root_name + '_sce2.txt', sep=\"\\n\", names=[\"raw_data\"], encoding = \"latin-1\")\n",
    "data_scene2 = pd.DataFrame()\n",
    "for x in range(len(column_names)):\n",
    "    data_scene2[column_names[x]] = data_scene2_raw[(data_scene2_raw.index + x) % 5== 0].reset_index(drop=True)\n",
    "    \n",
    "\n",
    "# Then we put the data from second scerion into pandas dataframe\n",
    "data_scene3_raw = pd.read_csv(data_path + output_file_root_name + '_sce3.txt', sep=\"\\n\", names=[\"raw_data\"], encoding = \"latin-1\")\n",
    "data_scene3 = pd.DataFrame()\n",
    "for x in range(len(column_names)):\n",
    "    data_scene3[column_names[x]] = data_scene3_raw[(data_scene3_raw.index + x) % 5== 0].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "# Remove the KOMONDOR SIMULATION string from colums!\n",
    "data_scene1[\"input_file_name\"] = data_scene1[\"input_file_name\"].str.replace(\"KOMONDOR SIMULATION 'sim_\", \"\")\n",
    "data_scene1[['input_file_name', 'seed']] = data_scene1['input_file_name'].str.split('(', 1, expand=True)\n",
    "data_scene1['input_file_name'] = data_scene1['input_file_name'].str.replace(\"'\", \"\")\n",
    "data_scene1[\"seed\"] = data_scene1[\"seed\"].str.replace(')', '', regex=True)\n",
    "\n",
    "data_scene2[\"input_file_name\"] = data_scene2[\"input_file_name\"].str.replace(\"KOMONDOR SIMULATION 'sim_\", \"\")\n",
    "data_scene2[['input_file_name', 'seed']] = data_scene2['input_file_name'].str.split('(', 1, expand=True)\n",
    "data_scene2['input_file_name'] = data_scene2['input_file_name'].str.replace(\"'\", \"\")\n",
    "data_scene2[\"seed\"] = data_scene2[\"seed\"].str.replace(')', '', regex=True)\n",
    "\n",
    "\n",
    "data_scene3[\"input_file_name\"] = data_scene3[\"input_file_name\"].str.replace(\"KOMONDOR SIMULATION 'sim_\", \"\")\n",
    "data_scene3[['input_file_name', 'seed']] = data_scene3['input_file_name'].str.split('(', 1, expand=True)\n",
    "data_scene3['input_file_name'] = data_scene3['input_file_name'].str.replace(\"'\", \"\")\n",
    "data_scene3[\"seed\"] = data_scene3[\"seed\"].str.replace(')', '', regex=True)\n",
    "\n",
    "#output_data_scene2.iloc[19446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9bf34e5-30de-4196-89ca-173fbc9d50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data based on the context and OBSS/PD information to the dataset\n",
    "data_scene1[\"context\"] = data_scene1[\"input_file_name\"].str.replace(\"input_nodes_s\", \"\")\n",
    "data_scene1[\"context\"] = data_scene1[\"context\"].str[:5].astype(int)\n",
    "data_scene1[\"OBSS_PD\"] = data_scene1[\"input_file_name\"].str[-7:-5].astype(int)\n",
    "data_scene1\n",
    "\n",
    "\n",
    "# Split the data based on the context\n",
    "data_scene2[\"context\"] = data_scene2[\"input_file_name\"].str[-14:-10].astype(int)  - 1000 # to get context between 0 and 2999\n",
    "data_scene2[\"OBSS_PD\"] = data_scene2[\"input_file_name\"].str[-7:-5].astype(int) \n",
    "#data_scene2\n",
    "\n",
    "# Split the data based on the context\n",
    "data_scene3[\"context\"] = data_scene3[\"input_file_name\"].str.replace(\"input_nodes_s\", \"\")\n",
    "data_scene3[\"context\"] = data_scene3[\"context\"].str.split(pat=\"_\") \n",
    "list_of_context = [] # there was some bug in reading the files...\n",
    "for row in  data_scene3[\"context\"]:\n",
    "    list_of_context.append(int(row[0]) + 1000) # to get context between 0 and 2999\n",
    "data_scene3[\"context\"] = list_of_context\n",
    "data_scene3[\"OBSS_PD\"] = data_scene3[\"input_file_name\"].str[-7:-5].astype(int)\n",
    "#data_scene3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd0773e-b773-411a-a11c-d007f0ceb602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 999 2000 2999 1000 1999\n"
     ]
    }
   ],
   "source": [
    "print(data_scene1[\"context\"].min(),\n",
    "data_scene1[\"context\"].max(),\n",
    "data_scene2[\"context\"].min(),\n",
    "data_scene2[\"context\"].max(),\n",
    "data_scene3[\"context\"].min(),\n",
    "data_scene3[\"context\"].max(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61fe24e-0a9b-429f-aa60-c892ad8ce16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions for reading the dataset\n",
    "def read_output_simulator(fp, dataset_lenght):       \n",
    "    RSSI_list = [] \n",
    "    SINR_list = [] \n",
    "    interference_list = [] \n",
    "    throughput_list = []\n",
    "    # To manually fix bugs in the dataset\n",
    "    RSSI_bugs = [np.array([-80.77,-81.19,-65.59]), np.array([-61.77,-62.19,-46.59]), np.array([-61.77,-62.19,-46.59]),\n",
    "                np.array([-61.77,-62.19,-46.59]), np.array([-61.77,-62.19,-46.59]), np.array([-61.77,-62.19,-46.59]), \n",
    "                np.array([-61.77,-62.19,-46.59]), np.array([-61.77,-62.19,-46.59])] \n",
    "    RSSI_bug_index = 0\n",
    "    \n",
    "     # To manually fix bugs in the dataset\n",
    "    SINR_bugs = [np.array([35.05, 33.56]), np.array([35.16, 30.83]), np.array([33.95, 34.76, 39.32]), np.array([32.91,31.65,47.57]),\n",
    "                np.array([32.89,31.68,47.43]), np.array([32.92,31.72,47.38]), np.array([32.69,31.58,47.12]) , np.array([32.73,31.56,47.44]), \n",
    "                np.array([32.48,31.67,47.61]), np.array([32.74,31.67,47.27]), np.array([32.74,31.61,47.59]), np.array([32.91,31.67,47.61])]\n",
    "    SINR_bug_index = 0\n",
    "    \n",
    "    fp = fp.readlines()\n",
    "    line_index = 0 \n",
    "    for index in range(dataset_lenght):\n",
    "        try:\n",
    "            line = fp[line_index]                  # Initial line (name of the scenaio)\n",
    "            line_index += 1\n",
    "        except:\n",
    "            print(\"The problematic index is\", line_index)\n",
    "            line_index += 1\n",
    "        #print(\"reading...\",line)\n",
    "        # Throughput \n",
    "        throughput = fp[line_index]                 # Throughput\n",
    "        line_index += 1\n",
    "        throughput = throughput.strip()         # Remove \\n ch\n",
    "        if \",\" in throughput:\n",
    "            throughput = np.array(throughput[0:len(throughput)].split(',')).astype(np.float)\n",
    "            throughput_list.append(throughput)\n",
    "        else:\n",
    "            try:\n",
    "                throughput = float(throughput)\n",
    "            except:\n",
    "                print(\"There is an throughput data bug at line \", line_index, \"raw data is\",  throughput)\n",
    "                print(throughput)\n",
    "                throughput = 0.0\n",
    "            throughput_list.append(throughput)\n",
    "        \n",
    "        # Interferences\n",
    "        interference = fp[line_index]             # Interferences\n",
    "        interference = interference.strip()     # Remove \\n ch\n",
    "        line_index += 1\n",
    "        if \",\" in interference:\n",
    "            interference = np.array(interference[0:len(interference)].split(',')).astype(np.float)\n",
    "            interference_list.append(interference)\n",
    "        else:\n",
    "            interference = float(interference)\n",
    "            interference_list.append(interference)\n",
    "        \n",
    "        # RSSI\n",
    "        RSSI = fp[line_index]           # RSSI\n",
    "        RSSI = RSSI.strip()         # Remove \\n ch\n",
    "        line_index += 1\n",
    "        if \",\" in RSSI:\n",
    "            try:\n",
    "                RSSI = np.array(RSSI[0:len(RSSI)].split(',')).astype(np.float)\n",
    "            except:\n",
    "                print(\"There is an RSSI data bug at line \",line_index, \"raw data is\",  RSSI)\n",
    "                RSSI = RSSI_bugs[RSSI_bug_index]\n",
    "                RSSI_bug_index += 1\n",
    "            RSSI_list.append(RSSI)\n",
    "        else:\n",
    "            RSSI = float(RSSI)\n",
    "            RSSI_list.append(RSSI)\n",
    "            \n",
    "        # SINR\n",
    "        SINR = fp[line_index]          # SINR\n",
    "        SINR = SINR.strip()         # Remove \\n ch\n",
    "        line_index += 1\n",
    "        \n",
    "        if \",\" in SINR:\n",
    "            #SINR.replace('«¤Ð', '')\n",
    "            #SINR = np.array(SINR[0:len(SINR)].split(',')).astype(np.float)\n",
    "            #SINR_list.append(SINR)\n",
    "            try:\n",
    "                SINR = np.array(SINR[0:len(SINR)].split(',')).astype(np.float)\n",
    "            except:\n",
    "                print(\"There is an SINR data bug at line \",line_index, \"raw data is\",  SINR)\n",
    "                SINR = SINR_bugs[SINR_bug_index] # Push in manual corrections\n",
    "                SINR_bug_index += 1  \n",
    "            SINR_list.append(SINR)\n",
    "        else:\n",
    "            SINR = SINR.replace('f', '')  # As there is a bug in the dataset\n",
    "            SINR = float(SINR)\n",
    "            SINR_list.append(SINR)\n",
    "\n",
    "    return( RSSI_list, SINR_list, interference_list, throughput_list)\n",
    "\n",
    "\n",
    "def read_input_files(input_dataset_path, input_dataset_names_list):\n",
    "    \"\"\"\n",
    "    A functions that returns input information, currently we only append the data we think is required...\n",
    "    \n",
    "    \n",
    "    All options are below:\n",
    "    \n",
    "    ['node_code', 'node_type', 'wlan_code', 'x(m)', 'y(m)', 'z(m)', 'central_freq(GHz)', \n",
    "    'channel_bonding_model', 'primary_channel', 'min_channel_allowed', 'max_channel_allowed', \n",
    "    'tpc_default(dBm)', 'cca_default(dBm)', 'traffic_model', 'traffic_load[pkt/s]',\n",
    "    'packet_length', 'num_packets_aggregated', 'capture_effect_model',\n",
    "    'capture_effect_thr', 'constant_per', 'pifs_activated', 'cw_adaptation',\n",
    "    'cont_wind', 'cont_wind_stage', 'bss_color', 'spatial_reuse_group',\n",
    "    'non_srg_obss_pd', 'srg_obss_pd']\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    list_node_type = []\n",
    "    x_pos_list = []\n",
    "    y_pos_list = []\n",
    "    \n",
    "    for dataset_name in input_dataset_names_list:\n",
    "        df  = pd.read_csv(input_dataset_path + dataset_name[1:-1], sep = ';', usecols=['node_type', 'x(m)', 'y(m)'])\n",
    "        list_node_type.append(df['node_type'].tolist())\n",
    "        x_pos_list.append(df['x(m)'].tolist())\n",
    "        y_pos_list.append(df['y(m)'].tolist())\n",
    "        # Add what you need in this line...\n",
    "        \n",
    "\n",
    "    return list_node_type, x_pos_list, y_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0901be60-1e2d-4554-b08d-05e1bf26105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD RSSI, Interference, SNR, and Throughput to the dataframe\n",
    "output_train_sim_sce1 = output_train_sim+'output_11ax_sr_simulations_sce1.txt'\n",
    "output_train_sim_sce2 = output_train_sim+'output_11ax_sr_simulations_sce2.txt'\n",
    "output_train_sim_sce3 = output_train_sim+'output_11ax_sr_simulations_sce3.txt'\n",
    "\n",
    "\n",
    "fp1 = open(output_train_sim_sce1, 'r')\n",
    "RSSI, SINR, interference, throughput = read_output_simulator(fp1, len(data_scene1))\n",
    "data_scene1[\"RSSI\"] = RSSI\n",
    "data_scene1[\"SINR\"] = SINR\n",
    "data_scene1[\"interference\"] = interference\n",
    "data_scene1[\"throughput\"] = throughput\n",
    "\n",
    "\n",
    "fp2 = open(output_train_sim_sce2, 'r', encoding = \"latin-1\")\n",
    "RSSI, SINR, interference, throughput = read_output_simulator(fp2, len(data_scene2))\n",
    "data_scene2[\"RSSI\"] = RSSI\n",
    "data_scene2[\"SINR\"] = SINR\n",
    "data_scene2[\"interference\"] = interference\n",
    "data_scene2[\"throughput\"] = throughput\n",
    "\n",
    "\n",
    "fp3 = open(output_train_sim_sce3, 'r', encoding = \"latin-1\")\n",
    "RSSI, SINR, interference, throughput = read_output_simulator(fp3, len(data_scene3))\n",
    "data_scene3[\"RSSI\"] = RSSI\n",
    "data_scene3[\"SINR\"] = SINR\n",
    "data_scene3[\"interference\"] = interference\n",
    "data_scene3[\"throughput\"] = throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f2ed8af-63e6-4aaa-9119-c85fb70e081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the input information to the dataframe as will be used, note this takes a while...try to make it more efficient\n",
    "input_dataset_path1 = data_path+'simulator_input_files_sce1/'\n",
    "input_dataset_path2 = data_path+'simulator_input_files_sce2/'\n",
    "input_dataset_path3 = data_path+'simulator_input_files_sce3/'\n",
    "\n",
    "node_types, x_positions, y_postions = read_input_files(input_dataset_path1, data_scene1['input_file_name'].tolist())\n",
    "data_scene1[\"node_type\"] = node_types\n",
    "data_scene1[\"x(m)\"] = x_positions\n",
    "data_scene1[\"y(m)\"] = y_postions\n",
    "\n",
    "node_types, x_positions, y_postions = read_input_files(input_dataset_path2, data_scene2['input_file_name'].tolist())\n",
    "data_scene2[\"node_type\"] = node_types\n",
    "data_scene2[\"x(m)\"] = x_positions\n",
    "data_scene2[\"y(m)\"] = y_postions\n",
    "\n",
    "\n",
    "node_types, x_positions, y_postions = read_input_files(input_dataset_path3, data_scene3['input_file_name'].tolist())\n",
    "data_scene3[\"node_type\"] = node_types\n",
    "data_scene3[\"x(m)\"] = x_positions\n",
    "data_scene3[\"y(m)\"] = y_postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314c845a-922c-467f-8f49-d502cd3e6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataset and save it to a file using pickle (to preserve the original datatypes) extension\n",
    "entire_dataset = pd.concat([data_scene1, data_scene2, data_scene3], ignore_index=True)\n",
    "entire_dataset\n",
    "#save to csv file\n",
    "#entire_dataset.to_csv('cleaned_dataset/train.csv', index=False)\n",
    "\n",
    "#pq.write_table(pa.Table.from_pandas(entire_dataset), 'cleaned_dataset/train.parquet')\n",
    "entire_dataset.to_pickle('cleaned_dataset/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f6219f-3432-40f0-97b5-4e298b03615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example on how to read the .pikle file\n",
    "#dataset_train = pd.read_csv('cleaned_dataset/train.csv')\n",
    "dataset_train = pd.read_pickle('cleaned_dataset/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2671e737-7c0b-4959-8ccc-c46780979690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entire_dataset.loc[entire_dataset['context'] == 1191])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "821d1ae3-b92b-4d4a-95f3-920c5eda181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1004, 1025, 1116, 1124, 1142, 1163, 1185, 1191, 1205, 1208, 1209, 1224, 1236, 1242, 1260, 1282, 1295, 1302, 1312, 1318, 1324, 1341, 1348, 1373, 1405, 1407, 1422, 1471, 1485, 1503, 1514, 1520, 1590, 1601, 1640, 1670, 1681, 1693, 1730, 1742, 1766, 1771, 1792, 1810, 1811, 1818, 1842, 1856, 1880, 1903, 1931, 1943, 1966, 1990] 54\n"
     ]
    }
   ],
   "source": [
    "list_of_context_that_do_not_exist = []\n",
    "for i in range(3000):\n",
    "    if len(entire_dataset.loc[entire_dataset['context'] == i])  < 1:\n",
    "        #print(i)\n",
    "        list_of_context_that_do_not_exist.append(i)\n",
    "print(list_of_context_that_do_not_exist, len(list_of_context_that_do_not_exist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c6c0e-8c63-4051-84f8-0e9db9136d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
